{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please comment out the dataset you don't want\n",
    "df = pd.read_excel('booking_sentiment.xlsx',sheet_name='summary')\n",
    "#df = pd.read_excel('TwitterSentiment.xlsx',sheet_name='summary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "X = df['message']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      location perfect  very nice and attentive staf...\n",
       "1                           good location  helpful staff\n",
       "2      great value for money nice swimming pool nice ...\n",
       "3      i am pretty tall and big man and here is one o...\n",
       "4      the location was excellent   the restraint was...\n",
       "                             ...                        \n",
       "134    so bad  we have joined for four nights but onl...\n",
       "135                                  gym was a bit small\n",
       "136    the only thing i can say is not so good is the...\n",
       "137    pool towels disgusting have thrown better in t...\n",
       "138    very poor repesentation of by the hotel staff ...\n",
       "Name: message, Length: 139, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean the number\n",
    "X = X.apply(lambda x: re.sub('\\d','num',x.lower()))\n",
    "#Clean the punctuation\n",
    "X = X.apply(lambda x: re.sub('\\-|\\,|\\.|\\!',' ',x.lower()))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/euer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download stop word from nltk (So we don't need to define it ourselve)\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = list(X)\n",
    "type(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/euer/Documents/GitHub/ML_template/NLP/Sentiment_Analysis_101.ipynb Cell 9'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/euer/Documents/GitHub/ML_template/NLP/Sentiment_Analysis_101.ipynb#ch0000008?line=0'>1</a>\u001b[0m cv_doc \u001b[39m=\u001b[39m CountVectorizer(document)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "cv_doc = CountVectorizer(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv_doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/euer/Documents/GitHub/ML_template/NLP/Sentiment_Analysis_101.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/euer/Documents/GitHub/ML_template/NLP/Sentiment_Analysis_101.ipynb#ch0000009?line=0'>1</a>\u001b[0m cv_vector \u001b[39m=\u001b[39m cv_doc\u001b[39m.\u001b[39mfit_transform(document)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv_doc' is not defined"
     ]
    }
   ],
   "source": [
    " cv_vector = cv_doc.fit_transform(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolutely',\n",
       " 'ac',\n",
       " 'acceptable',\n",
       " 'access',\n",
       " 'accomodating',\n",
       " 'across',\n",
       " 'action',\n",
       " 'add',\n",
       " 'additional',\n",
       " 'adelphi',\n",
       " 'adequate',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adults',\n",
       " 'aerier',\n",
       " 'afternoons',\n",
       " 'aging',\n",
       " 'air',\n",
       " 'aircon',\n",
       " 'allowed',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'also',\n",
       " 'always',\n",
       " 'amateur',\n",
       " 'amenities',\n",
       " 'amount',\n",
       " 'apparently',\n",
       " 'approach',\n",
       " 'approx',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'armost',\n",
       " 'around',\n",
       " 'arrived',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'attendant',\n",
       " 'attentive',\n",
       " 'available',\n",
       " 'average',\n",
       " 'away',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'baht',\n",
       " 'balcony',\n",
       " 'bangkok',\n",
       " 'bar',\n",
       " 'bars',\n",
       " 'basic',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'beach',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'beside',\n",
       " 'best',\n",
       " 'better',\n",
       " 'beyond',\n",
       " 'big',\n",
       " 'bin',\n",
       " 'bit',\n",
       " 'bizarre',\n",
       " 'blurry',\n",
       " 'body',\n",
       " 'book',\n",
       " 'booking',\n",
       " 'bored',\n",
       " 'bottom',\n",
       " 'breakfast',\n",
       " 'breakfasts',\n",
       " 'bring',\n",
       " 'brother',\n",
       " 'buakhao',\n",
       " 'buffet',\n",
       " 'building',\n",
       " 'bukhao',\n",
       " 'bukhoew',\n",
       " 'bus',\n",
       " 'busy',\n",
       " 'calm',\n",
       " 'camp',\n",
       " 'cannot',\n",
       " 'card',\n",
       " 'care',\n",
       " 'center',\n",
       " 'central',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chair',\n",
       " 'change',\n",
       " 'channels',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charges',\n",
       " 'cheap',\n",
       " 'cheapest',\n",
       " 'check',\n",
       " 'cheese',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choose',\n",
       " 'class',\n",
       " 'clean',\n",
       " 'cleaned',\n",
       " 'cleaning',\n",
       " 'cleanliness',\n",
       " 'clear',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'clothes',\n",
       " 'cold',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comfi',\n",
       " 'comfortable',\n",
       " 'comfy',\n",
       " 'coming',\n",
       " 'con',\n",
       " 'condition',\n",
       " 'conditioning',\n",
       " 'connection',\n",
       " 'connections',\n",
       " 'considerably',\n",
       " 'considered',\n",
       " 'construction',\n",
       " 'continent',\n",
       " 'continental',\n",
       " 'cost',\n",
       " 'cosy',\n",
       " 'could',\n",
       " 'course',\n",
       " 'courteous',\n",
       " 'covid',\n",
       " 'crowded',\n",
       " 'currently',\n",
       " 'customer',\n",
       " 'dark',\n",
       " 'day',\n",
       " 'days',\n",
       " 'deal',\n",
       " 'decent',\n",
       " 'delicious',\n",
       " 'deluxe',\n",
       " 'demand',\n",
       " 'description',\n",
       " 'device',\n",
       " 'devils',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'direct',\n",
       " 'disgusting',\n",
       " 'distance',\n",
       " 'disturbing',\n",
       " 'diverse',\n",
       " 'done',\n",
       " 'door',\n",
       " 'doors',\n",
       " 'downtown',\n",
       " 'drinks',\n",
       " 'drive',\n",
       " 'dropped',\n",
       " 'droppings',\n",
       " 'drying',\n",
       " 'due',\n",
       " 'duplex',\n",
       " 'early',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eating',\n",
       " 'efficient',\n",
       " 'egg',\n",
       " 'elevator',\n",
       " 'end',\n",
       " 'english',\n",
       " 'enjoyable',\n",
       " 'enjoyed',\n",
       " 'enough',\n",
       " 'entrance',\n",
       " 'equipment',\n",
       " 'equipped',\n",
       " 'erratic',\n",
       " 'escape',\n",
       " 'escaped',\n",
       " 'especially',\n",
       " 'establishment',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'every',\n",
       " 'everyday',\n",
       " 'everything',\n",
       " 'exactly',\n",
       " 'excellent',\n",
       " 'exceptionally',\n",
       " 'exceĺlent',\n",
       " 'exept',\n",
       " 'expectation',\n",
       " 'expected',\n",
       " 'expecting',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'extend',\n",
       " 'extra',\n",
       " 'extremely',\n",
       " 'face',\n",
       " 'facilities',\n",
       " 'facility',\n",
       " 'fairly',\n",
       " 'fake',\n",
       " 'falls',\n",
       " 'family',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'fault',\n",
       " 'feels',\n",
       " 'festival',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'first',\n",
       " 'fitness',\n",
       " 'floor',\n",
       " 'food',\n",
       " 'foreigners',\n",
       " 'found',\n",
       " 'four',\n",
       " 'free',\n",
       " 'fridge',\n",
       " 'friendliness',\n",
       " 'friendly',\n",
       " 'front',\n",
       " 'furnitures',\n",
       " 'get',\n",
       " 'giant',\n",
       " 'girlfriends',\n",
       " 'girls',\n",
       " 'give',\n",
       " 'glazing',\n",
       " 'go',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'got',\n",
       " 'great',\n",
       " 'greatstay',\n",
       " 'group',\n",
       " 'groups',\n",
       " 'grumble',\n",
       " 'guess',\n",
       " 'guest',\n",
       " 'guests',\n",
       " 'gym',\n",
       " 'hallways',\n",
       " 'handset',\n",
       " 'hard',\n",
       " 'haunted',\n",
       " 'hazardous',\n",
       " 'heard',\n",
       " 'heavy',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'high',\n",
       " 'hot',\n",
       " 'hotel',\n",
       " 'hotels',\n",
       " 'hotter',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'however',\n",
       " 'humid',\n",
       " 'hustle',\n",
       " 'improve',\n",
       " 'improved',\n",
       " 'indian',\n",
       " 'indians',\n",
       " 'interested',\n",
       " 'intermittently',\n",
       " 'internal',\n",
       " 'international',\n",
       " 'internet',\n",
       " 'isolation',\n",
       " 'issue',\n",
       " 'jacket',\n",
       " 'joined',\n",
       " 'joiner',\n",
       " 'jotimen',\n",
       " 'keep',\n",
       " 'kept',\n",
       " 'key',\n",
       " 'keys',\n",
       " 'kilometer',\n",
       " 'kiniauw',\n",
       " 'kitchen',\n",
       " 'kitchens',\n",
       " 'lack',\n",
       " 'lady',\n",
       " 'large',\n",
       " 'last',\n",
       " 'late',\n",
       " 'leaves',\n",
       " 'less',\n",
       " 'life',\n",
       " 'lift',\n",
       " 'like',\n",
       " 'limited',\n",
       " 'little',\n",
       " 'lively',\n",
       " 'lk',\n",
       " 'local',\n",
       " 'located',\n",
       " 'location',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'lots',\n",
       " 'loud',\n",
       " 'lounger',\n",
       " 'loved',\n",
       " 'lovely',\n",
       " 'low',\n",
       " 'luggage',\n",
       " 'machines',\n",
       " 'made',\n",
       " 'main',\n",
       " 'maintained',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'mall',\n",
       " 'man',\n",
       " 'many',\n",
       " 'maps',\n",
       " 'market',\n",
       " 'massage',\n",
       " 'massages',\n",
       " 'mattress',\n",
       " 'may',\n",
       " 'mentioning',\n",
       " 'menu',\n",
       " 'meter',\n",
       " 'metro',\n",
       " 'mid',\n",
       " 'middle',\n",
       " 'mine',\n",
       " 'minutes',\n",
       " 'money',\n",
       " 'mopeds',\n",
       " 'morning',\n",
       " 'mostly',\n",
       " 'moto',\n",
       " 'motorcycle',\n",
       " 'move',\n",
       " 'much',\n",
       " 'm²',\n",
       " 'naughty',\n",
       " 'near',\n",
       " 'nearby',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'needs',\n",
       " 'neighbour',\n",
       " 'neighbours',\n",
       " 'nesting',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'nightlife',\n",
       " 'nightmarket',\n",
       " 'nights',\n",
       " 'nobody',\n",
       " 'noise',\n",
       " 'noisy',\n",
       " 'none',\n",
       " 'normal',\n",
       " 'north',\n",
       " 'nothing',\n",
       " 'num',\n",
       " 'numnum',\n",
       " 'numnumc',\n",
       " 'numnumnum',\n",
       " 'numnumnumnum',\n",
       " 'numnumpm',\n",
       " 'numpm',\n",
       " 'numth',\n",
       " 'obviously',\n",
       " 'offer',\n",
       " 'ok',\n",
       " 'old',\n",
       " 'one',\n",
       " 'onward',\n",
       " 'open',\n",
       " 'operate',\n",
       " 'opposite',\n",
       " 'option',\n",
       " 'outside',\n",
       " 'overall',\n",
       " 'overlooked',\n",
       " 'overpriced',\n",
       " 'paid',\n",
       " 'paper',\n",
       " 'parking',\n",
       " 'parlour',\n",
       " 'part',\n",
       " 'party',\n",
       " 'patio',\n",
       " 'pattaya',\n",
       " 'pavements',\n",
       " 'peaceful',\n",
       " 'people',\n",
       " 'perfect',\n",
       " 'period',\n",
       " 'personal',\n",
       " 'picking',\n",
       " 'pictures',\n",
       " 'pigeon',\n",
       " 'pigeons',\n",
       " 'pillows',\n",
       " 'place',\n",
       " 'places',\n",
       " 'pleasant',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'polite',\n",
       " 'pool',\n",
       " 'poor',\n",
       " 'porters',\n",
       " 'possible',\n",
       " 'preparations',\n",
       " 'present',\n",
       " 'preset',\n",
       " 'pressure',\n",
       " 'pretty',\n",
       " 'price',\n",
       " 'problem',\n",
       " 'professional',\n",
       " 'provided',\n",
       " 'pumping',\n",
       " 'put',\n",
       " 'questions',\n",
       " 'queue',\n",
       " 'quiet',\n",
       " 'quieter',\n",
       " 'quite',\n",
       " 'ranging',\n",
       " 'rather',\n",
       " 'really',\n",
       " 'reasonably',\n",
       " 'receive',\n",
       " 'reception',\n",
       " 'refund',\n",
       " 'refunds',\n",
       " 'refused',\n",
       " 'releasing',\n",
       " 'repesentation',\n",
       " 'request',\n",
       " 'required',\n",
       " 'requirements',\n",
       " 'restaurant',\n",
       " 'restaurants',\n",
       " 'restraint',\n",
       " 'resturants',\n",
       " 'return',\n",
       " 'ridicoulus',\n",
       " 'right',\n",
       " 'ripped',\n",
       " 'road',\n",
       " 'roads',\n",
       " 'roof',\n",
       " 'rooftop',\n",
       " 'room',\n",
       " 'rooms',\n",
       " 'route',\n",
       " 'rude',\n",
       " 'running',\n",
       " 'rushed',\n",
       " 'safety',\n",
       " 'said',\n",
       " 'salami',\n",
       " 'saved',\n",
       " 'say',\n",
       " 'scary',\n",
       " 'school',\n",
       " 'sea',\n",
       " 'second',\n",
       " 'secure',\n",
       " 'seems',\n",
       " 'selection',\n",
       " 'self',\n",
       " 'sense',\n",
       " 'serious',\n",
       " 'service',\n",
       " 'set',\n",
       " 'shop',\n",
       " 'shopping',\n",
       " 'short',\n",
       " 'shower',\n",
       " 'side',\n",
       " 'siesta',\n",
       " 'situation',\n",
       " 'size',\n",
       " 'sleep',\n",
       " 'slept',\n",
       " 'slide',\n",
       " 'slippers',\n",
       " 'slow',\n",
       " 'small',\n",
       " 'smaller',\n",
       " 'smelly',\n",
       " 'smile',\n",
       " 'smiling',\n",
       " 'soft',\n",
       " 'soi',\n",
       " 'solid',\n",
       " 'somebody',\n",
       " 'sometimes',\n",
       " 'sorry',\n",
       " 'sort',\n",
       " 'sound',\n",
       " 'sounds',\n",
       " 'space',\n",
       " 'spaciou',\n",
       " 'spacious',\n",
       " 'speak',\n",
       " 'special',\n",
       " 'specious',\n",
       " 'speed',\n",
       " 'staff',\n",
       " 'staffs',\n",
       " 'standard',\n",
       " 'star',\n",
       " 'stars',\n",
       " 'start',\n",
       " 'starts',\n",
       " 'station',\n",
       " 'stay',\n",
       " 'stayed',\n",
       " 'steps',\n",
       " 'still',\n",
       " 'stole',\n",
       " 'stop',\n",
       " 'stops',\n",
       " 'street',\n",
       " 'streets',\n",
       " 'strong',\n",
       " 'sub',\n",
       " 'suit',\n",
       " 'supplying',\n",
       " 'supportive',\n",
       " 'supposed',\n",
       " 'sure',\n",
       " 'surprisingly',\n",
       " 'swimming',\n",
       " 'swimmingpool',\n",
       " 'swinning',\n",
       " 'taken',\n",
       " 'taking',\n",
       " 'talks',\n",
       " 'tall',\n",
       " 'taxi',\n",
       " 'taxis',\n",
       " 'taxistand',\n",
       " 'temperature',\n",
       " 'terrible',\n",
       " 'testy',\n",
       " 'thb',\n",
       " 'therefore',\n",
       " 'thieves',\n",
       " 'thin',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'though',\n",
       " 'three',\n",
       " 'throughout',\n",
       " 'thrown',\n",
       " 'tight',\n",
       " 'time',\n",
       " 'times',\n",
       " 'toilet',\n",
       " 'toothbrushes',\n",
       " 'top',\n",
       " 'tour',\n",
       " 'tours',\n",
       " 'towards',\n",
       " 'towels',\n",
       " 'town',\n",
       " 'track',\n",
       " 'trainers',\n",
       " 'tree',\n",
       " 'tried',\n",
       " 'trip',\n",
       " 'triple',\n",
       " 'trust',\n",
       " 'trying',\n",
       " 'tv',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'un',\n",
       " 'uncomfortable',\n",
       " 'understand',\n",
       " 'understanding',\n",
       " 'understood',\n",
       " 'unfortunate',\n",
       " 'unfortunately',\n",
       " 'upgrade',\n",
       " 'upstairs',\n",
       " 'useful',\n",
       " 'using',\n",
       " 'value',\n",
       " 'variety',\n",
       " 'view',\n",
       " 'visited',\n",
       " 'vs',\n",
       " 'wait',\n",
       " 'walk',\n",
       " 'walking',\n",
       " 'walls',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'washing',\n",
       " 'water',\n",
       " 'way',\n",
       " 'week',\n",
       " 'weight',\n",
       " 'welcomed',\n",
       " 'welcoming',\n",
       " 'well',\n",
       " 'whorehouse',\n",
       " 'wifi',\n",
       " 'windows',\n",
       " 'within',\n",
       " 'without',\n",
       " 'work',\n",
       " 'working',\n",
       " 'works',\n",
       " 'worst',\n",
       " 'would',\n",
       " 'yet']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv_doc.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 312)\t1\n",
      "  (0, 411)\t1\n",
      "  (0, 366)\t1\n",
      "  (0, 38)\t1\n",
      "  (0, 528)\t1\n",
      "  (0, 103)\t1\n",
      "  (0, 243)\t1\n",
      "  (0, 53)\t1\n",
      "  (0, 18)\t1\n",
      "  (1, 312)\t1\n",
      "  (1, 528)\t1\n",
      "  (1, 243)\t1\n",
      "  (1, 262)\t1\n",
      "  (2, 312)\t1\n",
      "  (2, 366)\t2\n",
      "  (2, 245)\t1\n",
      "  (2, 609)\t1\n",
      "  (2, 347)\t1\n",
      "  (2, 553)\t1\n",
      "  (2, 425)\t1\n",
      "  (2, 144)\t1\n",
      "  (2, 471)\t1\n",
      "  (2, 357)\t1\n",
      "  (2, 308)\t1\n",
      "  (2, 419)\t1\n",
      "  :\t:\n",
      "  (138, 97)\t1\n",
      "  (138, 537)\t1\n",
      "  (138, 265)\t2\n",
      "  (138, 214)\t1\n",
      "  (138, 616)\t1\n",
      "  (138, 626)\t1\n",
      "  (138, 543)\t1\n",
      "  (138, 367)\t2\n",
      "  (138, 577)\t1\n",
      "  (138, 450)\t1\n",
      "  (138, 426)\t1\n",
      "  (138, 131)\t1\n",
      "  (138, 33)\t1\n",
      "  (138, 597)\t1\n",
      "  (138, 219)\t1\n",
      "  (138, 52)\t1\n",
      "  (138, 455)\t1\n",
      "  (138, 297)\t1\n",
      "  (138, 474)\t1\n",
      "  (138, 510)\t1\n",
      "  (138, 207)\t1\n",
      "  (138, 487)\t1\n",
      "  (138, 257)\t1\n",
      "  (138, 138)\t1\n",
      "  (138, 292)\t1\n"
     ]
    }
   ],
   "source": [
    "print(cv_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'sum_axis_0.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_word = {cv_doc.get_feature_names()[i]:v for i,v in enumerate(cv_vector.toarray().sum(axis=0))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 57),\n",
       " ('staff', 46),\n",
       " ('breakfast', 41),\n",
       " ('room', 36),\n",
       " ('hotel', 35),\n",
       " ('location', 35),\n",
       " ('clean', 28),\n",
       " ('pool', 24),\n",
       " ('nice', 21),\n",
       " ('friendly', 18),\n",
       " ('great', 18),\n",
       " ('num', 16),\n",
       " ('helpful', 15),\n",
       " ('rooms', 12),\n",
       " ('could', 11),\n",
       " ('night', 11),\n",
       " ('also', 10),\n",
       " ('like', 10),\n",
       " ('service', 10),\n",
       " ('shower', 10),\n",
       " ('swimming', 10),\n",
       " ('numnum', 9),\n",
       " ('value', 9),\n",
       " ('well', 9),\n",
       " ('bars', 8),\n",
       " ('bed', 8),\n",
       " ('money', 8),\n",
       " ('noisy', 8),\n",
       " ('pattaya', 8),\n",
       " ('bit', 7),\n",
       " ('close', 7),\n",
       " ('due', 7),\n",
       " ('everything', 7),\n",
       " ('outside', 7),\n",
       " ('star', 7),\n",
       " ('street', 7),\n",
       " ('walk', 7),\n",
       " ('walking', 7),\n",
       " ('water', 7),\n",
       " ('air', 6),\n",
       " ('area', 6),\n",
       " ('best', 6),\n",
       " ('check', 6),\n",
       " ('cleaning', 6),\n",
       " ('excellent', 6),\n",
       " ('far', 6),\n",
       " ('gym', 6),\n",
       " ('loud', 6),\n",
       " ('minutes', 6),\n",
       " ('nights', 6),\n",
       " ('poor', 6),\n",
       " ('quiet', 6),\n",
       " ('restaurants', 6),\n",
       " ('would', 6),\n",
       " ('better', 5),\n",
       " ('big', 5),\n",
       " ('cold', 5),\n",
       " ('comfortable', 5),\n",
       " ('enough', 5),\n",
       " ('little', 5),\n",
       " ('many', 5),\n",
       " ('much', 5),\n",
       " ('one', 5),\n",
       " ('pretty', 5),\n",
       " ('really', 5),\n",
       " ('soi', 5),\n",
       " ('stay', 5),\n",
       " ('stayed', 5),\n",
       " ('around', 4),\n",
       " ('charge', 4),\n",
       " ('day', 4),\n",
       " ('decent', 4),\n",
       " ('english', 4),\n",
       " ('equipment', 4),\n",
       " ('even', 4),\n",
       " ('expected', 4),\n",
       " ('facilities', 4),\n",
       " ('food', 4),\n",
       " ('go', 4),\n",
       " ('lot', 4),\n",
       " ('massage', 4),\n",
       " ('need', 4),\n",
       " ('numnumnumnum', 4),\n",
       " ('problem', 4),\n",
       " ('quite', 4),\n",
       " ('right', 4),\n",
       " ('road', 4),\n",
       " ('rooftop', 4),\n",
       " ('set', 4),\n",
       " ('size', 4),\n",
       " ('small', 4),\n",
       " ('time', 4),\n",
       " ('wifi', 4),\n",
       " ('aircon', 3),\n",
       " ('always', 3),\n",
       " ('away', 3),\n",
       " ('bad', 3),\n",
       " ('balcony', 3),\n",
       " ('bar', 3),\n",
       " ('bath', 3),\n",
       " ('bedroom', 3),\n",
       " ('buakhao', 3),\n",
       " ('central', 3),\n",
       " ('cleaned', 3),\n",
       " ('closed', 3),\n",
       " ('covid', 3),\n",
       " ('find', 3),\n",
       " ('fine', 3),\n",
       " ('four', 3),\n",
       " ('get', 3),\n",
       " ('give', 3),\n",
       " ('hot', 3),\n",
       " ('however', 3),\n",
       " ('lack', 3),\n",
       " ('large', 3),\n",
       " ('limited', 3),\n",
       " ('lovely', 3),\n",
       " ('near', 3),\n",
       " ('nearby', 3),\n",
       " ('noise', 3),\n",
       " ('ok', 3),\n",
       " ('open', 3),\n",
       " ('place', 3),\n",
       " ('places', 3),\n",
       " ('price', 3),\n",
       " ('professional', 3),\n",
       " ('reception', 3),\n",
       " ('selection', 3),\n",
       " ('slow', 3),\n",
       " ('sometimes', 3),\n",
       " ('spacious', 3),\n",
       " ('still', 3),\n",
       " ('taxi', 3),\n",
       " ('temperature', 3),\n",
       " ('thb', 3),\n",
       " ('thing', 3),\n",
       " ('think', 3),\n",
       " ('top', 3),\n",
       " ('tried', 3),\n",
       " ('variety', 3),\n",
       " ('ac', 2),\n",
       " ('access', 2),\n",
       " ('adelphi', 2),\n",
       " ('almost', 2),\n",
       " ('arrived', 2),\n",
       " ('baht', 2),\n",
       " ('basic', 2),\n",
       " ('bathroom', 2),\n",
       " ('beach', 2),\n",
       " ('body', 2),\n",
       " ('book', 2),\n",
       " ('booking', 2),\n",
       " ('buffet', 2),\n",
       " ('bus', 2),\n",
       " ('busy', 2),\n",
       " ('care', 2),\n",
       " ('center', 2),\n",
       " ('con', 2),\n",
       " ('condition', 2),\n",
       " ('currently', 2),\n",
       " ('customer', 2),\n",
       " ('days', 2),\n",
       " ('deal', 2),\n",
       " ('distance', 2),\n",
       " ('done', 2),\n",
       " ('door', 2),\n",
       " ('drinks', 2),\n",
       " ('early', 2),\n",
       " ('easy', 2),\n",
       " ('eating', 2),\n",
       " ('end', 2),\n",
       " ('equipped', 2),\n",
       " ('especially', 2),\n",
       " ('every', 2),\n",
       " ('expecting', 2),\n",
       " ('family', 2),\n",
       " ('fault', 2),\n",
       " ('first', 2),\n",
       " ('floor', 2),\n",
       " ('found', 2),\n",
       " ('fridge', 2),\n",
       " ('got', 2),\n",
       " ('guests', 2),\n",
       " ('hard', 2),\n",
       " ('improve', 2),\n",
       " ('internet', 2),\n",
       " ('lift', 2),\n",
       " ('lively', 2),\n",
       " ('lost', 2),\n",
       " ('lots', 2),\n",
       " ('low', 2),\n",
       " ('machines', 2),\n",
       " ('mostly', 2),\n",
       " ('motorcycle', 2),\n",
       " ('needs', 2),\n",
       " ('neighbour', 2),\n",
       " ('next', 2),\n",
       " ('nightlife', 2),\n",
       " ('north', 2),\n",
       " ('numnumnum', 2),\n",
       " ('old', 2),\n",
       " ('opposite', 2),\n",
       " ('parking', 2),\n",
       " ('parlour', 2),\n",
       " ('perfect', 2),\n",
       " ('pillows', 2),\n",
       " ('rather', 2),\n",
       " ('refused', 2),\n",
       " ('roof', 2),\n",
       " ('say', 2),\n",
       " ('second', 2),\n",
       " ('short', 2),\n",
       " ('situation', 2),\n",
       " ('smaller', 2),\n",
       " ('space', 2),\n",
       " ('sub', 2),\n",
       " ('terrible', 2),\n",
       " ('though', 2),\n",
       " ('three', 2),\n",
       " ('town', 2),\n",
       " ('tv', 2),\n",
       " ('two', 2),\n",
       " ('understand', 2),\n",
       " ('unfortunately', 2),\n",
       " ('upstairs', 2),\n",
       " ('wait', 2),\n",
       " ('walls', 2),\n",
       " ('want', 2),\n",
       " ('week', 2),\n",
       " ('welcoming', 2),\n",
       " ('within', 2),\n",
       " ('works', 2),\n",
       " ('absolutely', 1),\n",
       " ('acceptable', 1),\n",
       " ('accomodating', 1),\n",
       " ('across', 1),\n",
       " ('action', 1),\n",
       " ('add', 1),\n",
       " ('additional', 1),\n",
       " ('adequate', 1),\n",
       " ('adjust', 1),\n",
       " ('adjusted', 1),\n",
       " ('adults', 1),\n",
       " ('aerier', 1),\n",
       " ('afternoons', 1),\n",
       " ('aging', 1),\n",
       " ('allowed', 1),\n",
       " ('allows', 1),\n",
       " ('amateur', 1),\n",
       " ('amenities', 1),\n",
       " ('amount', 1),\n",
       " ('apparently', 1),\n",
       " ('approach', 1),\n",
       " ('approx', 1),\n",
       " ('areas', 1),\n",
       " ('armost', 1),\n",
       " ('asia', 1),\n",
       " ('asian', 1),\n",
       " ('attendant', 1),\n",
       " ('attentive', 1),\n",
       " ('available', 1),\n",
       " ('average', 1),\n",
       " ('back', 1),\n",
       " ('bangkok', 1),\n",
       " ('beside', 1),\n",
       " ('beyond', 1),\n",
       " ('bin', 1),\n",
       " ('bizarre', 1),\n",
       " ('blurry', 1),\n",
       " ('bored', 1),\n",
       " ('bottom', 1),\n",
       " ('breakfasts', 1),\n",
       " ('bring', 1),\n",
       " ('brother', 1),\n",
       " ('building', 1),\n",
       " ('bukhao', 1),\n",
       " ('bukhoew', 1),\n",
       " ('calm', 1),\n",
       " ('camp', 1),\n",
       " ('cannot', 1),\n",
       " ('card', 1),\n",
       " ('certain', 1),\n",
       " ('certainly', 1),\n",
       " ('chair', 1),\n",
       " ('change', 1),\n",
       " ('channels', 1),\n",
       " ('charged', 1),\n",
       " ('charges', 1),\n",
       " ('cheap', 1),\n",
       " ('cheapest', 1),\n",
       " ('cheese', 1),\n",
       " ('choice', 1),\n",
       " ('choices', 1),\n",
       " ('choose', 1),\n",
       " ('class', 1),\n",
       " ('cleanliness', 1),\n",
       " ('clear', 1),\n",
       " ('closer', 1),\n",
       " ('clothes', 1),\n",
       " ('com', 1),\n",
       " ('come', 1),\n",
       " ('comfi', 1),\n",
       " ('comfy', 1),\n",
       " ('coming', 1),\n",
       " ('conditioning', 1),\n",
       " ('connection', 1),\n",
       " ('connections', 1),\n",
       " ('considerably', 1),\n",
       " ('considered', 1),\n",
       " ('construction', 1),\n",
       " ('continent', 1),\n",
       " ('continental', 1),\n",
       " ('cost', 1),\n",
       " ('cosy', 1),\n",
       " ('course', 1),\n",
       " ('courteous', 1),\n",
       " ('crowded', 1),\n",
       " ('dark', 1),\n",
       " ('delicious', 1),\n",
       " ('deluxe', 1),\n",
       " ('demand', 1),\n",
       " ('description', 1),\n",
       " ('device', 1),\n",
       " ('devils', 1),\n",
       " ('difference', 1),\n",
       " ('different', 1),\n",
       " ('direct', 1),\n",
       " ('disgusting', 1),\n",
       " ('disturbing', 1),\n",
       " ('diverse', 1),\n",
       " ('doors', 1),\n",
       " ('downtown', 1),\n",
       " ('drive', 1),\n",
       " ('dropped', 1),\n",
       " ('droppings', 1),\n",
       " ('drying', 1),\n",
       " ('duplex', 1),\n",
       " ('easily', 1),\n",
       " ('eat', 1),\n",
       " ('efficient', 1),\n",
       " ('egg', 1),\n",
       " ('elevator', 1),\n",
       " ('enjoyable', 1),\n",
       " ('enjoyed', 1),\n",
       " ('entrance', 1),\n",
       " ('erratic', 1),\n",
       " ('escape', 1),\n",
       " ('escaped', 1),\n",
       " ('establishment', 1),\n",
       " ('etc', 1),\n",
       " ('evening', 1),\n",
       " ('everyday', 1),\n",
       " ('exactly', 1),\n",
       " ('exceptionally', 1),\n",
       " ('exceĺlent', 1),\n",
       " ('exept', 1),\n",
       " ('expectation', 1),\n",
       " ('expensive', 1),\n",
       " ('experience', 1),\n",
       " ('extend', 1),\n",
       " ('extra', 1),\n",
       " ('extremely', 1),\n",
       " ('face', 1),\n",
       " ('facility', 1),\n",
       " ('fairly', 1),\n",
       " ('fake', 1),\n",
       " ('falls', 1),\n",
       " ('fast', 1),\n",
       " ('feels', 1),\n",
       " ('festival', 1),\n",
       " ('fitness', 1),\n",
       " ('foreigners', 1),\n",
       " ('free', 1),\n",
       " ('friendliness', 1),\n",
       " ('front', 1),\n",
       " ('furnitures', 1),\n",
       " ('giant', 1),\n",
       " ('girlfriends', 1),\n",
       " ('girls', 1),\n",
       " ('glazing', 1),\n",
       " ('going', 1),\n",
       " ('gone', 1),\n",
       " ('greatstay', 1),\n",
       " ('group', 1),\n",
       " ('groups', 1),\n",
       " ('grumble', 1),\n",
       " ('guess', 1),\n",
       " ('guest', 1),\n",
       " ('hallways', 1),\n",
       " ('handset', 1),\n",
       " ('haunted', 1),\n",
       " ('hazardous', 1),\n",
       " ('heard', 1),\n",
       " ('heavy', 1),\n",
       " ('help', 1),\n",
       " ('high', 1),\n",
       " ('hotels', 1),\n",
       " ('hotter', 1),\n",
       " ('hour', 1),\n",
       " ('hours', 1),\n",
       " ('humid', 1),\n",
       " ('hustle', 1),\n",
       " ('improved', 1),\n",
       " ('indian', 1),\n",
       " ('indians', 1),\n",
       " ('interested', 1),\n",
       " ('intermittently', 1),\n",
       " ('internal', 1),\n",
       " ('international', 1),\n",
       " ('isolation', 1),\n",
       " ('issue', 1),\n",
       " ('jacket', 1),\n",
       " ('joined', 1),\n",
       " ('joiner', 1),\n",
       " ('jotimen', 1),\n",
       " ('keep', 1),\n",
       " ('kept', 1),\n",
       " ('key', 1),\n",
       " ('keys', 1),\n",
       " ('kilometer', 1),\n",
       " ('kiniauw', 1),\n",
       " ('kitchen', 1),\n",
       " ('kitchens', 1),\n",
       " ('lady', 1),\n",
       " ('last', 1),\n",
       " ('late', 1),\n",
       " ('leaves', 1),\n",
       " ('less', 1),\n",
       " ('life', 1),\n",
       " ('lk', 1),\n",
       " ('local', 1),\n",
       " ('located', 1),\n",
       " ('long', 1),\n",
       " ('longer', 1),\n",
       " ('lounger', 1),\n",
       " ('loved', 1),\n",
       " ('luggage', 1),\n",
       " ('made', 1),\n",
       " ('main', 1),\n",
       " ('maintained', 1),\n",
       " ('make', 1),\n",
       " ('makes', 1),\n",
       " ('mall', 1),\n",
       " ('man', 1),\n",
       " ('maps', 1),\n",
       " ('market', 1),\n",
       " ('massages', 1),\n",
       " ('mattress', 1),\n",
       " ('may', 1),\n",
       " ('mentioning', 1),\n",
       " ('menu', 1),\n",
       " ('meter', 1),\n",
       " ('metro', 1),\n",
       " ('mid', 1),\n",
       " ('middle', 1),\n",
       " ('mine', 1),\n",
       " ('mopeds', 1),\n",
       " ('morning', 1),\n",
       " ('moto', 1),\n",
       " ('move', 1),\n",
       " ('m²', 1),\n",
       " ('naughty', 1),\n",
       " ('needed', 1),\n",
       " ('neighbours', 1),\n",
       " ('nesting', 1),\n",
       " ('nightmarket', 1),\n",
       " ('nobody', 1),\n",
       " ('none', 1),\n",
       " ('normal', 1),\n",
       " ('nothing', 1),\n",
       " ('numnumc', 1),\n",
       " ('numnumpm', 1),\n",
       " ('numpm', 1),\n",
       " ('numth', 1),\n",
       " ('obviously', 1),\n",
       " ('offer', 1),\n",
       " ('onward', 1),\n",
       " ('operate', 1),\n",
       " ('option', 1),\n",
       " ('overall', 1),\n",
       " ('overlooked', 1),\n",
       " ('overpriced', 1),\n",
       " ('paid', 1),\n",
       " ('paper', 1),\n",
       " ('part', 1),\n",
       " ('party', 1),\n",
       " ('patio', 1),\n",
       " ('pavements', 1),\n",
       " ('peaceful', 1),\n",
       " ('people', 1),\n",
       " ('period', 1),\n",
       " ('personal', 1),\n",
       " ('picking', 1),\n",
       " ('pictures', 1),\n",
       " ('pigeon', 1),\n",
       " ('pigeons', 1),\n",
       " ('pleasant', 1),\n",
       " ('please', 1),\n",
       " ('plus', 1),\n",
       " ('polite', 1),\n",
       " ('porters', 1),\n",
       " ('possible', 1),\n",
       " ('preparations', 1),\n",
       " ('present', 1),\n",
       " ('preset', 1),\n",
       " ('pressure', 1),\n",
       " ('provided', 1),\n",
       " ('pumping', 1),\n",
       " ('put', 1),\n",
       " ('questions', 1),\n",
       " ('queue', 1),\n",
       " ('quieter', 1),\n",
       " ('ranging', 1),\n",
       " ('reasonably', 1),\n",
       " ('receive', 1),\n",
       " ('refund', 1),\n",
       " ('refunds', 1),\n",
       " ('releasing', 1),\n",
       " ('repesentation', 1),\n",
       " ('request', 1),\n",
       " ('required', 1),\n",
       " ('requirements', 1),\n",
       " ('restaurant', 1),\n",
       " ('restraint', 1),\n",
       " ('resturants', 1),\n",
       " ('return', 1),\n",
       " ('ridicoulus', 1),\n",
       " ('ripped', 1),\n",
       " ('roads', 1),\n",
       " ('route', 1),\n",
       " ('rude', 1),\n",
       " ('running', 1),\n",
       " ('rushed', 1),\n",
       " ('safety', 1),\n",
       " ('said', 1),\n",
       " ('salami', 1),\n",
       " ('saved', 1),\n",
       " ('scary', 1),\n",
       " ('school', 1),\n",
       " ('sea', 1),\n",
       " ('secure', 1),\n",
       " ('seems', 1),\n",
       " ('self', 1),\n",
       " ('sense', 1),\n",
       " ('serious', 1),\n",
       " ('shop', 1),\n",
       " ('shopping', 1),\n",
       " ('side', 1),\n",
       " ('siesta', 1),\n",
       " ('sleep', 1),\n",
       " ('slept', 1),\n",
       " ('slide', 1),\n",
       " ('slippers', 1),\n",
       " ('smelly', 1),\n",
       " ('smile', 1),\n",
       " ('smiling', 1),\n",
       " ('soft', 1),\n",
       " ('solid', 1),\n",
       " ('somebody', 1),\n",
       " ('sorry', 1),\n",
       " ('sort', 1),\n",
       " ('sound', 1),\n",
       " ('sounds', 1),\n",
       " ('spaciou', 1),\n",
       " ('speak', 1),\n",
       " ('special', 1),\n",
       " ('specious', 1),\n",
       " ('speed', 1),\n",
       " ('staffs', 1),\n",
       " ('standard', 1),\n",
       " ('stars', 1),\n",
       " ('start', 1),\n",
       " ('starts', 1),\n",
       " ('station', 1),\n",
       " ('steps', 1),\n",
       " ('stole', 1),\n",
       " ('stop', 1),\n",
       " ('stops', 1),\n",
       " ('streets', 1),\n",
       " ('strong', 1),\n",
       " ('suit', 1),\n",
       " ('supplying', 1),\n",
       " ('supportive', 1),\n",
       " ('supposed', 1),\n",
       " ('sure', 1),\n",
       " ('surprisingly', 1),\n",
       " ('swimmingpool', 1),\n",
       " ('swinning', 1),\n",
       " ('taken', 1),\n",
       " ('taking', 1),\n",
       " ('talks', 1),\n",
       " ('tall', 1),\n",
       " ('taxis', 1),\n",
       " ('taxistand', 1),\n",
       " ('testy', 1),\n",
       " ('therefore', 1),\n",
       " ('thieves', 1),\n",
       " ('thin', 1),\n",
       " ('throughout', 1),\n",
       " ('thrown', 1),\n",
       " ('tight', 1),\n",
       " ('times', 1),\n",
       " ('toilet', 1),\n",
       " ('toothbrushes', 1),\n",
       " ('tour', 1),\n",
       " ('tours', 1),\n",
       " ('towards', 1),\n",
       " ('towels', 1),\n",
       " ('track', 1),\n",
       " ('trainers', 1),\n",
       " ('tree', 1),\n",
       " ('trip', 1),\n",
       " ('triple', 1),\n",
       " ('trust', 1),\n",
       " ('trying', 1),\n",
       " ('twice', 1),\n",
       " ('un', 1),\n",
       " ('uncomfortable', 1),\n",
       " ('understanding', 1),\n",
       " ('understood', 1),\n",
       " ('unfortunate', 1),\n",
       " ('upgrade', 1),\n",
       " ('useful', 1),\n",
       " ('using', 1),\n",
       " ('view', 1),\n",
       " ('visited', 1),\n",
       " ('vs', 1),\n",
       " ('wanted', 1),\n",
       " ('washing', 1),\n",
       " ('way', 1),\n",
       " ('weight', 1),\n",
       " ('welcomed', 1),\n",
       " ('whorehouse', 1),\n",
       " ('windows', 1),\n",
       " ('without', 1),\n",
       " ('work', 1),\n",
       " ('working', 1),\n",
       " ('worst', 1),\n",
       " ('yet', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the most mentioned words from imput (excluded stopwords)\n",
    "sorted(sum_word.items(),key= lambda item:item[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<139x639 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1512 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will be input(X) accordingly\n",
    "cv_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = cv_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model to be compare\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "svc = SVC()\n",
    "nb = GaussianNB()\n",
    "mlp = MLPClassifier()\n",
    "ada = AdaBoostClassifier()\n",
    "ensemble_clf = [dt,svc,nb,mlp,ada]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_DecisionTreeClassifier() accuracy =  0.8214285714285714\n",
      "y_pred_SVC() accuracy =  0.9285714285714286\n",
      "y_pred_GaussianNB() accuracy =  0.8928571428571429\n",
      "y_pred_MLPClassifier() accuracy =  0.8928571428571429\n",
      "y_pred_AdaBoostClassifier() accuracy =  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "#For model nb, there is some adjustment for X needed\n",
    "for model in [dt,svc,nb,mlp,ada]:\n",
    "    if model != nb:\n",
    "        clf = model.fit(X_train,y_train)\n",
    "        globals()[f'y_pred_{model}'] = clf.predict(X_test)\n",
    "        print(f'y_pred_{model} accuracy = ',accuracy_score(globals()[f'y_pred_{model}'],y_test))\n",
    "    else:\n",
    "        clf = model.fit(X_train.toarray(),y_train)\n",
    "        globals()[f'y_pred_{model}'] = clf.predict(X_test.toarray())\n",
    "        print(f'y_pred_{model} accuracy = ',accuracy_score(globals()[f'y_pred_{model}'],y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Twitter_performance.png' width=480>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Booking Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Booking_performance.png' width = 480>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning hyperparameter with GridCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1={\"max_depth\": range(5,30,5), \"min_samples_leaf\": range(1,30,2)}\n",
    "params2={\"kernel\":['sigmoid','linear','rbf']}\n",
    "params3={}\n",
    "params4={'solver': ['lbfgs'], 'max_iter': [1000], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15),'learning_rate' :['constant','adaptive']}\n",
    "params5={'n_estimators':[50,100,150,200],'learning_rate':np.arange(0.1,1,0.1)}\n",
    "parameters_list=[params1, params2, params3, params4,params5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = ['_dt','_svc','_nb','_mlp','_ada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_DecisionTreeClassifier() best params:  {'max_depth': 20, 'min_samples_leaf': 1}\n",
      "y_pred_DecisionTreeClassifier() accuracy =  0.8214285714285714\n",
      "y_pred_SVC() best params:  {'kernel': 'sigmoid'}\n",
      "y_pred_SVC() accuracy =  0.9285714285714286\n",
      "y_pred_GaussianNB() best params:  {}\n",
      "y_pred_GaussianNB() accuracy =  0.8928571428571429\n",
      "y_pred_MLPClassifier() best params:  {'alpha': 0.001, 'hidden_layer_sizes': 14, 'learning_rate': 'constant', 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "y_pred_MLPClassifier() accuracy =  0.8928571428571429\n",
      "y_pred_AdaBoostClassifier() best params:  {'learning_rate': 0.6, 'n_estimators': 150}\n",
      "y_pred_AdaBoostClassifier() accuracy =  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "#For model nb, there is some adjustment for X needed\n",
    "for i in range(len(ensemble_clf)):\n",
    "    if i != 2:\n",
    "        clf = GridSearchCV(estimator = ensemble_clf[i],param_grid=parameters_list[i],cv=3).fit(X_train,y_train)\n",
    "        globals()[f'y_pred_{ensemble_clf[i]}'] = clf.predict(X_test)\n",
    "        print(f'y_pred_{ensemble_clf[i]} best params: ',clf.best_params_)\n",
    "        print(f'y_pred_{ensemble_clf[i]} accuracy = ',accuracy_score(globals()[f'y_pred_{ensemble_clf[i]}'],y_test))\n",
    "    else:\n",
    "        clf = GridSearchCV(estimator = ensemble_clf[i],param_grid=parameters_list[i],cv=3).fit(X_train.toarray(),y_train)\n",
    "        globals()[f'y_pred_{ensemble_clf[i]}'] = clf.predict(X_test.toarray())\n",
    "        print(f'y_pred_{ensemble_clf[i]} best params: ',clf.best_params_)\n",
    "        print(f'y_pred_{ensemble_clf[i]} accuracy = ',accuracy_score(globals()[f'y_pred_{ensemble_clf[i]}'],y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "1. Performance\n",
    "   - Twitter dataset : Naive Bayes (GB) performed the best with 85.7% accuracy\n",
    "   - Booking dataset : SVC performed the best with 92.8% accuracy\n",
    "   - The performance is quite good interms of accuracy but that because of the test set unique words are included in the trainning set already </br>\n",
    "   ,so there is no words that the training set haven't seen which make the performance so good.\n",
    "   - In my opinion, this is very surprising that the performance is this high, especially for booking dataset, however, the set unique words in the data </br>\n",
    "   set seems to be very narrow </br></br>\n",
    "2. Improvement\n",
    "   - As the sentiment analysis need lots more datapoints for the sake of having bigger bag of words which provide more realiable result.\n",
    "   - More adjustment for data preprocessing such as ignore the outlier, drop the mispell might help enhacing the performance."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
